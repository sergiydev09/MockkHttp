# MockkHttp Performance Optimization Guide

## üìä Executive Summary

Este documento detalla los problemas de rendimiento cr√≠ticos encontrados en MockkHttp cuando se usa en escenarios de **alta carga** (proyectos grandes con cientos de requests simult√°neas y m√∫ltiples proyectos Android Studio abiertos).

**Objetivo**: Hacer que el plugin funcione de manera eficiente sin limitar funcionalidad, soportando:
- ‚úÖ Cientos de requests simult√°neas por segundo
- ‚úÖ M√∫ltiples proyectos Android Studio abiertos
- ‚úÖ Apps que hacen cientos de llamadas HTTP
- ‚úÖ Modo Debug sin colapsar la app o el plugin

---

## üî¥ PROBLEMA 1: Thread Explosion - Thread Pool sin L√≠mites

### Ubicaci√≥n
**Archivo**: `GlobalOkHttpInterceptorServer.kt:307-309`

### Problema Actual
```kotlin
// Handle each client in separate thread
thread(isDaemon = true) {
    handleClient(clientSocket)
}
```

**Impacto**:
- Crea un thread NUEVO por cada request HTTP sin l√≠mite alguno
- 100 requests simult√°neas = 100 threads activos
- 500 requests = 500 threads ‚Üí **Colapso total del sistema**
- Cada thread consume ~1MB de stack + overhead del scheduler
- CPU se satura haciendo context switching entre cientos de threads

### Soluci√≥n Propuesta
Implementar **Kotlin Coroutines con Channel para Backpressure**:

```kotlin
@Service(Service.Level.APP)
class GlobalOkHttpInterceptorServer {

    private val logger = Logger.getInstance(GlobalOkHttpInterceptorServer::class.java)
    private val gson = Gson()

    // CoroutineScope para el servidor
    private val serverScope = CoroutineScope(
        SupervisorJob() +
        Dispatchers.IO +
        CoroutineName("MockkHttp-GlobalServer")
    )

    // Channel con backpressure (buffer limitado)
    private val requestChannel = Channel<Socket>(capacity = 500)  // Buffer de 500 requests

    private var serverSocket: ServerSocket? = null
    private var isRunning = false

    @Synchronized
    fun ensureStarted(): Boolean {
        if (isRunning) return true

        logger.info("üöÄ Starting Global OkHttp Interceptor Server on port $SERVER_PORT")

        return try {
            serverSocket = ServerSocket(SERVER_PORT)
            isRunning = true

            // Lanzar servidor en coroutine
            serverScope.launch {
                runServer()
            }

            // Lanzar workers (pool de coroutines para procesar requests)
            repeat(50) { workerId ->  // 50 workers concurrentes
                serverScope.launch {
                    processRequests(workerId)
                }
            }

            logger.info("‚úÖ Global interceptor server listening on port $SERVER_PORT")
            true

        } catch (e: Exception) {
            logger.error("‚ùå Failed to start global interceptor server", e)
            isRunning = false
            false
        }
    }

    /**
     * Server loop - acepta conexiones y las env√≠a al channel.
     */
    private suspend fun runServer() {
        logger.info("üîÑ Global server loop started")
        try {
            while (isRunning) {
                try {
                    val clientSocket = withContext(Dispatchers.IO) {
                        serverSocket?.accept()
                    } ?: break

                    logger.debug("üì± Client connected: ${clientSocket.inetAddress.hostAddress}")

                    // Enviar al channel (con backpressure)
                    // Si el channel est√° lleno, esta l√≠nea SUSPENDE (no bloquea thread)
                    try {
                        requestChannel.send(clientSocket)
                    } catch (e: ClosedSendChannelException) {
                        logger.debug("Channel closed, rejecting connection")
                        clientSocket.close()
                        break
                    }

                } catch (e: SocketException) {
                    if (isRunning) logger.error("Socket error", e)
                    break
                } catch (e: Exception) {
                    if (isRunning) logger.error("Error accepting client connection", e)
                }
            }
        } finally {
            logger.debug("Global server loop ended")
        }
    }

    /**
     * Worker coroutine - procesa requests del channel.
     * M√∫ltiples workers pueden procesar concurrentemente.
     */
    private suspend fun processRequests(workerId: Int) {
        logger.debug("Worker $workerId started")

        try {
            for (clientSocket in requestChannel) {  // Consume del channel
                try {
                    handleClient(clientSocket)
                } catch (e: Exception) {
                    logger.error("Worker $workerId: Error handling client", e)
                }
            }
        } finally {
            logger.debug("Worker $workerId stopped")
        }
    }

    /**
     * Handle a single client connection (ahora es suspending function).
     */
    private suspend fun handleClient(socket: Socket) {
        withContext(Dispatchers.IO) {
            socket.use { clientSocket ->
                try {
                    val reader = BufferedReader(clientSocket.getInputStream().reader())
                    val writer = PrintWriter(clientSocket.getOutputStream(), true)

                    val json = reader.readLine()
                    if (json == null) {
                        logger.debug("Client disconnected without sending data")
                        return@use
                    }

                    // Handle PING
                    if (json == "PING") {
                        writer.println("PONG")
                        logger.debug("üì° PING received, sent PONG")
                        return@use
                    }

                    // Parse and route flow
                    val flowData = gson.fromJson(json, AndroidFlowData::class.java)
                    logger.debug("${flowData.request.method} ${flowData.request.url}")

                    val response = routeFlow(flowData)
                    writer.println(gson.toJson(response))

                } catch (e: Exception) {
                    logger.error("Error handling client", e)
                }
            }
        }
    }

    @Synchronized
    private fun stop() {
        if (!isRunning) return

        logger.info("üõë Stopping global interceptor server...")
        isRunning = false

        try {
            // Cerrar channel (workers terminan cuando consumen pendientes)
            requestChannel.close()

            // Cancelar scope (cancela todas las coroutines)
            serverScope.cancel()

            serverSocket?.close()
            logger.info("‚úÖ Global interceptor server stopped")
        } catch (e: Exception) {
            logger.error("Error stopping global server", e)
        }

        serverSocket = null
    }
}
```

**Beneficios de Coroutines sobre ExecutorService**:
- ‚úÖ **Lightweight**: 50 coroutines ‚âà 500KB vs 50 threads ‚âà 50MB de memoria
- ‚úÖ **Backpressure nativo**: `Channel.send()` suspende (no bloquea) cuando est√° lleno
- ‚úÖ **Structured concurrency**: `serverScope.cancel()` limpia todo autom√°ticamente
- ‚úÖ **Non-blocking I/O**: `accept()` y `handleClient()` liberan threads mientras esperan
- ‚úÖ **Escalable**: Soporta 100,000+ coroutines concurrentes vs ~1,000 threads max

**Esfuerzo**: ~3 horas (incluye agregar dependencia de coroutines si no est√°)
**Prioridad**: üî¥ CR√çTICA

---

## üî¥ PROBLEMA 2: Debug Mode Blocking - Bloqueo Masivo de Threads

### Ubicaci√≥n
- **Archivo 1**: `OkHttpInterceptorServer.kt:270-346` (`showInterceptDialogAndWait()`)
- **Archivo 2**: `MockkHttpInterceptor.kt:212-254` (Android side)

### Problema Actual

**En Plugin (IntelliJ)**:
```kotlin
private fun showInterceptDialogAndWait(flowData: HttpFlowData): Pair<ModifiedResponseData, Boolean> {
    val latch = CountDownLatch(1)

    SwingUtilities.invokeLater {
        val dialog = DebugInterceptDialog(project, flowData)
        dialog.showAndGet()  // MODAL DIALOG - bloquea hasta que usuario act√∫e
        latch.countDown()
    }

    latch.await(5, TimeUnit.MINUTES)  // BLOQUEA THREAD DEL SOCKET ‚ö†Ô∏è
}
```

**En Android App**:
```kotlin
// MockkHttpInterceptor.kt:231
// WAIT for modified response (blocks thread)
val reader = it.getInputStream().bufferedReader()
val modifiedJson = reader.readLine()  // BLOQUEA THREAD DE OkHttp ‚ö†Ô∏è
```

**Impacto en cascada**:
1. Usuario abre Debug Mode
2. App hace 100 requests simult√°neas
3. Cada request crea un thread en GlobalServer (PROBLEMA #1)
4. Cada thread queda BLOQUEADO esperando que el usuario cierre el di√°logo
5. **100 di√°logos apilados** esperando atenci√≥n del usuario
6. 100 threads bloqueados en Android consumiendo el pool de OkHttp
7. La app se congela porque OkHttp no tiene threads disponibles
8. El plugin se ralentiza porque tiene 100 threads zombie

### Soluci√≥n Propuesta

**Implementar Queue con Coroutines + CompletableDeferred**:

```kotlin
@Service(Service.Level.PROJECT)
class OkHttpInterceptorServer(private val project: Project) {

    // CoroutineScope del proyecto
    private val projectScope = CoroutineScope(
        SupervisorJob() +
        Dispatchers.Default +
        CoroutineName("MockkHttp-Project-${project.name}")
    )

    // StateFlow para pending debug requests (observable en UI)
    private val pendingDebugRequests = MutableStateFlow<List<PendingDebugRequest>>(emptyList())

    data class PendingDebugRequest(
        val flowId: String,
        val flowData: HttpFlowData,
        val timestamp: Long,
        val responseDeferred: CompletableDeferred<ModifiedResponseData>  // Promesa de respuesta
    )

    /**
     * Handle flow - ahora es suspending function.
     */
    private suspend fun handleFlow(androidFlow: AndroidFlowData): ModifiedResponseData {
        val httpFlowData = convertToHttpFlowData(androidFlow)

        return when (currentMode) {
            Mode.RECORDING -> {
                flowStore.addFlow(httpFlowData)
                ModifiedResponseData.original()
            }

            Mode.DEBUG -> {
                // Agregar a queue de debug
                val deferred = CompletableDeferred<ModifiedResponseData>()

                val pendingRequest = PendingDebugRequest(
                    flowId = httpFlowData.flowId,
                    flowData = httpFlowData,
                    timestamp = System.currentTimeMillis(),
                    responseDeferred = deferred
                )

                // Actualizar StateFlow (thread-safe, reactivo)
                pendingDebugRequests.update { current ->
                    current + pendingRequest
                }

                // Notificar UI que hay pending request
                withContext(Dispatchers.EDT) {  // EDT = Event Dispatch Thread
                    notifyPendingRequest()
                }

                // ESPERAR respuesta con timeout (SUSPENDE, no bloquea thread) ‚≠ê
                withTimeoutOrNull(30_000) {  // 30 segundos timeout
                    deferred.await()
                } ?: run {
                    // Timeout - remover de queue
                    pendingDebugRequests.update { current ->
                        current.filter { it.flowId != httpFlowData.flowId }
                    }
                    logger.warn("‚ö†Ô∏è Debug request timeout for ${httpFlowData.flowId}")
                    ModifiedResponseData.original()
                }
            }

            Mode.MOCKK -> {
                val matchingRule = findMatchingMockRule(httpFlowData)
                if (matchingRule != null) {
                    flowStore.addFlow(httpFlowData.copy(mockApplied = true))
                    ModifiedResponseData(
                        statusCode = matchingRule.statusCode,
                        headers = matchingRule.headers,
                        body = matchingRule.content
                    )
                } else {
                    flowStore.addFlow(httpFlowData)
                    ModifiedResponseData.original()
                }
            }

            Mode.MOCKK_DEBUG -> {
                // Similar a DEBUG pero con mock aplicado
                // ... (c√≥digo similar)
            }
        }
    }

    /**
     * M√©todo llamado desde UI cuando usuario responde al di√°logo.
     */
    fun respondToPendingRequest(flowId: String, response: ModifiedResponseData) {
        projectScope.launch {
            val request = pendingDebugRequests.value.find { it.flowId == flowId }

            if (request != null) {
                // Completar la promesa (desbloquea el await() en handleFlow)
                request.responseDeferred.complete(response)

                // Remover de queue
                pendingDebugRequests.update { current ->
                    current.filter { it.flowId != flowId }
                }

                logger.info("‚úÖ User responded to debug request: $flowId")
            }
        }
    }

    /**
     * UI Panel observa el StateFlow y muestra pending requests reactivamente.
     */
    fun observePendingRequests(onUpdate: (List<PendingDebugRequest>) -> Unit) {
        projectScope.launch(Dispatchers.EDT) {
            pendingDebugRequests.collect { pending ->
                onUpdate(pending)
            }
        }
    }
}
```

**UI Panel para pending requests**:

```kotlin
class InspectorPanel(private val project: Project) : JPanel(BorderLayout()) {

    private val pendingRequestsLabel = JLabel("Pending: 0")

    init {
        // Observar pending requests reactivamente
        interceptorServer.observePendingRequests { pending ->
            pendingRequestsLabel.text = "Pending: ${pending.size}"

            // Auto-mostrar di√°logo para el primero
            if (pending.isNotEmpty() && !isDialogOpen) {
                showDebugDialog(pending.first())
            }
        }
    }

    private fun showDebugDialog(request: PendingDebugRequest) {
        isDialogOpen = true

        val dialog = DebugInterceptDialog(project, request.flowData)
        dialog.show()

        // Cuando usuario cierra di√°logo, enviar respuesta
        val response = if (dialog.exitCode == DialogWrapper.OK_EXIT_CODE) {
            dialog.getModifiedResponse() ?: ModifiedResponseData.original()
        } else {
            ModifiedResponseData.original()
        }

        interceptorServer.respondToPendingRequest(request.flowId, response)
        isDialogOpen = false
    }
}
```

**Beneficios de Coroutines**:
- ‚úÖ **CompletableDeferred**: Promesa de respuesta, m√°s elegante que `CountDownLatch`
- ‚úÖ **No bloquea threads**: `await()` suspende la coroutine, libera el thread
- ‚úÖ **StateFlow**: Observable reactive, UI se actualiza autom√°ticamente
- ‚úÖ **Timeout integrado**: `withTimeoutOrNull()` built-in en coroutines
- ‚úÖ **Dispatchers.EDT**: Integraci√≥n nativa con EDT de IntelliJ
- ‚úÖ **Cancelaci√≥n estructurada**: Al cerrar proyecto, todo se limpia autom√°ticamente

**Esfuerzo**: ~7 horas (m√°s complejo pero mucho mejor arquitectura)
**Prioridad**: üî¥ CR√çTICA

---

## üî¥ PROBLEMA 3: Memory Explosion - FlowStore sin L√≠mites Efectivos

### Ubicaci√≥n
**Archivo**: `FlowStore.kt:40`

### Problema Actual
```kotlin
companion object {
    // Maximum number of flows to keep in memory
    private const val MAX_FLOWS = 1000
}
```

**C√°lculo real de memoria**:
- MAX_FLOWS = 1000
- Cada flow puede tener response body de hasta **5MB** (seg√∫n `MockkHttpInterceptor.kt:308`)
- Memoria potencial: 1000 √ó 5MB = **5GB** üî•

**Impacto**:
- Con una app que hace 100s de requests, se llena r√°pidamente
- Flows nunca se limpian hasta llegar a 1000
- Garbage Collector trabaja constantemente
- IntelliJ se ralentiza por presi√≥n de memoria

### Soluci√≥n Propuesta

**Implementar Memory Budget con Cleanup Inteligente**:

```kotlin
class FlowStore(project: Project) {

    companion object {
        // Configuraci√≥n de l√≠mites
        private const val MAX_FLOWS = 200  // Reducir de 1000 a 200
        private const val MAX_MEMORY_MB = 50  // M√°ximo 50MB de flows en memoria
        private const val LARGE_RESPONSE_THRESHOLD = 100_000  // 100KB
        private const val CLEANUP_AGE_MINUTES = 15  // Limpiar flows >15 min
    }

    // Tracking de memoria usada
    @Volatile
    private var estimatedMemoryUsageBytes = 0L

    fun addFlow(flow: HttpFlowData) {
        // Estimar tama√±o del flow
        val flowSize = estimateFlowSize(flow)

        // Si excede budget de memoria, hacer cleanup agresivo
        if (estimatedMemoryUsageBytes + flowSize > MAX_MEMORY_MB * 1024 * 1024) {
            logger.warn("‚ö†Ô∏è Memory budget exceeded, performing cleanup...")
            performMemoryCleanup()
        }

        // Comprimir response bodies grandes
        val optimizedFlow = if (flowSize > LARGE_RESPONSE_THRESHOLD) {
            compressLargeFlow(flow)
        } else {
            flow
        }

        flows[flow.flowId] = optimizedFlow
        flowOrder.add(flow.flowId)
        estimatedMemoryUsageBytes += flowSize

        // Cleanup por edad y cantidad
        while (flowOrder.size > MAX_FLOWS || shouldCleanupOldFlows()) {
            removeOldestFlow()
        }

        // Notificar listeners...
    }

    private fun estimateFlowSize(flow: HttpFlowData): Long {
        var size = 0L
        size += flow.request.url.length * 2  // chars = 2 bytes
        size += flow.request.content.length * 2
        size += flow.response?.content?.length?.times(2) ?: 0
        size += flow.request.headers.toString().length * 2
        size += flow.response?.headers?.toString()?.length?.times(2) ?: 0
        size += 500  // Overhead de objeto
        return size
    }

    private fun compressLargeFlow(flow: HttpFlowData): HttpFlowData {
        // Opci√≥n 1: Truncar response body
        val truncatedContent = flow.response?.content?.take(50_000) +
            "\n\n[... Response truncated to save memory. ${flow.response?.content?.length} total bytes]"

        return flow.copy(
            response = flow.response?.copy(content = truncatedContent)
        )

        // Opci√≥n 2: Comprimir con GZIP (m√°s avanzado)
        // return compressWithGzip(flow)
    }

    private fun performMemoryCleanup() {
        // 1. Remover flows >15 minutos
        val now = System.currentTimeMillis()
        val cutoffTime = now - (CLEANUP_AGE_MINUTES * 60 * 1000)

        flowOrder.toList().forEach { flowId ->
            val flow = flows[flowId]
            if (flow != null && flow.timestamp * 1000 < cutoffTime) {
                removeFlow(flowId)
                logger.debug("Cleaned up old flow: $flowId")
            }
        }

        // 2. Si todav√≠a excede memoria, remover flows m√°s grandes
        if (estimatedMemoryUsageBytes > MAX_MEMORY_MB * 1024 * 1024) {
            val sortedBySize = flows.values.sortedByDescending { estimateFlowSize(it) }
            sortedBySize.take(50).forEach { flow ->
                removeFlow(flow.flowId)
                logger.debug("Cleaned up large flow: ${flow.flowId}")
            }
        }
    }

    private fun shouldCleanupOldFlows(): Boolean {
        if (flowOrder.isEmpty()) return false

        val oldestId = flowOrder.firstOrNull() ?: return false
        val oldestFlow = flows[oldestId] ?: return false

        val ageMinutes = (System.currentTimeMillis() - oldestFlow.timestamp * 1000) / 60000
        return ageMinutes > CLEANUP_AGE_MINUTES
    }

    private fun removeFlow(flowId: String) {
        val removed = flows.remove(flowId)
        flowOrder.remove(flowId)

        if (removed != null) {
            estimatedMemoryUsageBytes -= estimateFlowSize(removed)
            if (removed.paused) pausedFlowsCount--
        }
    }
}
```

**Beneficios**:
- ‚úÖ Memoria predecible y controlada (m√°ximo 50MB)
- ‚úÖ Cleanup autom√°tico de flows antiguos
- ‚úÖ Compresi√≥n de responses grandes
- ‚úÖ Mejor rendimiento del GC

**Esfuerzo**: ~4 horas
**Prioridad**: üî¥ CR√çTICA

---

## üî¥ PROBLEMA 4: UI Blocking - Updates sin Batching

### Ubicaci√≥n
**Archivo**: `InspectorPanel.kt:231-258`

### Problema Actual
```kotlin
// Listen to flow changes
flowStore.addFlowAddedListener { flow ->
    SwingUtilities.invokeLater {
        allFlows.add(flow)
        // Apply filter
        if (matchesSearchQuery(flow, searchQuery)) {
            flowListModel.addElement(flow)  // Update UI INMEDIATAMENTE ‚ö†Ô∏è
        }
    }
}

flowStore.addFlowUpdatedListener { updatedFlow ->
    SwingUtilities.invokeLater {
        // Update in allFlows
        val indexInAll = allFlows.indexOfFirst { it.flowId == updatedFlow.flowId }  // O(n) ‚ö†Ô∏è
        if (indexInAll >= 0) {
            allFlows[indexInAll] = updatedFlow
        }

        // Update in filtered list if present
        for (i in 0 until flowListModel.size()) {  // O(n) OTRA VEZ ‚ö†Ô∏è
            val existingFlow = flowListModel.getElementAt(i)
            if (existingFlow.flowId == updatedFlow.flowId) {
                flowListModel.setElementAt(updatedFlow, i)
                break
            }
        }
    }
}
```

**Impacto**:
- 100 requests/segundo = 100 `SwingUtilities.invokeLater()` calls/segundo
- Cada update busca en lista completa con O(n)
- EDT (Event Dispatch Thread) se satura
- UI se congela y deja de responder
- Scrolling se vuelve lento

### Soluci√≥n Propuesta

**Implementar Reactive Streams con Flow (Kotlin Coroutines)**:

#### Paso 1: FlowStore con SharedFlow

```kotlin
@Service(Service.Level.PROJECT)
class FlowStore(project: Project) {

    // SharedFlow para emitir eventos (hot stream, m√∫ltiples collectors)
    private val _flowAdded = MutableSharedFlow<HttpFlowData>(
        extraBufferCapacity = 100,  // Buffer para evitar backpressure
        onBufferOverflow = BufferOverflow.DROP_OLDEST  // Drop antiguos si se llena
    )
    val flowAdded: SharedFlow<HttpFlowData> = _flowAdded.asSharedFlow()

    private val _flowUpdated = MutableSharedFlow<HttpFlowData>(
        extraBufferCapacity = 50,
        onBufferOverflow = BufferOverflow.DROP_OLDEST
    )
    val flowUpdated: SharedFlow<HttpFlowData> = _flowUpdated.asSharedFlow()

    private val _flowsCleared = MutableSharedFlow<Unit>(extraBufferCapacity = 10)
    val flowsCleared: SharedFlow<Unit> = _flowsCleared.asSharedFlow()

    fun addFlow(flow: HttpFlowData) {
        // ... l√≥gica de agregar flow ...

        // Emitir evento (non-blocking)
        _flowAdded.tryEmit(flow)
    }

    fun updateFlow(flow: HttpFlowData) {
        // ... l√≥gica de actualizar flow ...

        _flowUpdated.tryEmit(flow)
    }

    fun clearAllFlows() {
        flows.clear()
        flowOrder.clear()

        _flowsCleared.tryEmit(Unit)
    }
}
```

#### Paso 2: InspectorPanel con Reactive UI

```kotlin
class InspectorPanel(private val project: Project) : JPanel(BorderLayout()) {

    // CoroutineScope para el panel
    private val panelScope = CoroutineScope(
        SupervisorJob() +
        Dispatchers.Default +
        CoroutineName("InspectorPanel")
    )

    // HashMap para lookups O(1)
    private val flowsMap = ConcurrentHashMap<String, HttpFlowData>()
    private val allFlows = mutableListOf<HttpFlowData>()

    init {
        // Observar flows added con batching y debouncing autom√°tico
        panelScope.launch {
            flowStore.flowAdded
                .buffer(capacity = 50)  // Batching: acumula hasta 50 flows
                .chunked(50)  // Agrupa en lotes de m√°ximo 50
                .debounce(300)  // Espera 300ms de inactividad antes de procesar
                .flowOn(Dispatchers.Default)  // Procesar en background thread
                .collect { flowsBatch ->
                    // Actualizar en EDT
                    withContext(Dispatchers.EDT) {
                        processBatchAdd(flowsBatch)
                    }
                }
        }

        // Observar flows updated
        panelScope.launch {
            flowStore.flowUpdated
                .buffer(capacity = 50)
                .chunked(50)
                .debounce(300)
                .flowOn(Dispatchers.Default)
                .collect { flowsBatch ->
                    withContext(Dispatchers.EDT) {
                        processBatchUpdate(flowsBatch)
                    }
                }
        }

        // Observar flows cleared
        panelScope.launch(Dispatchers.EDT) {
            flowStore.flowsCleared.collect {
                flowsMap.clear()
                allFlows.clear()
                flowListModel.clear()
            }
        }
    }

    private fun processBatchAdd(flows: List<HttpFlowData>) {
        // Procesar batch de flows nuevos
        flows.forEach { flow ->
            flowsMap[flow.flowId] = flow
            allFlows.add(flow)

            if (matchesSearchQuery(flow, searchQuery)) {
                flowListModel.addElement(flow)
            }
        }

        logger.debug("Processed batch add: ${flows.size} flows")
    }

    private fun processBatchUpdate(flows: List<HttpFlowData>) {
        // Procesar batch de flows actualizados
        flows.forEach { updatedFlow ->
            flowsMap[updatedFlow.flowId] = updatedFlow

            // Update in allFlows
            val index = allFlows.indexOfFirst { it.flowId == updatedFlow.flowId }
            if (index >= 0) {
                allFlows[index] = updatedFlow
            }

            // Update in UI model
            for (i in 0 until flowListModel.size()) {
                if (flowListModel.getElementAt(i).flowId == updatedFlow.flowId) {
                    flowListModel.setElementAt(updatedFlow, i)
                    break
                }
            }
        }

        logger.debug("Processed batch update: ${flows.size} flows")
    }

    override fun removeNotify() {
        super.removeNotify()
        panelScope.cancel()  // Cleanup autom√°tico
    }
}
```

#### Extensi√≥n para `chunked()` con timeout

```kotlin
// Extensi√≥n √∫til para chunking con timeout
fun <T> Flow<T>.chunked(
    size: Int,
    timeoutMillis: Long = 500
): Flow<List<T>> = flow {
    val buffer = mutableListOf<T>()
    var lastEmitTime = System.currentTimeMillis()

    collect { value ->
        buffer.add(value)

        val now = System.currentTimeMillis()
        val shouldEmitBySize = buffer.size >= size
        val shouldEmitByTime = (now - lastEmitTime) >= timeoutMillis

        if (shouldEmitBySize || shouldEmitByTime) {
            emit(buffer.toList())
            buffer.clear()
            lastEmitTime = now
        }
    }

    // Emit remaining
    if (buffer.isNotEmpty()) {
        emit(buffer.toList())
    }
}
```

**Beneficios de Flow/Coroutines**:
- ‚úÖ **Batching autom√°tico**: `.buffer()` y `.chunked()` agrupan eventos
- ‚úÖ **Debouncing built-in**: `.debounce()` reduce frecuencia de updates
- ‚úÖ **Backpressure handling**: `BufferOverflow.DROP_OLDEST` evita overflow
- ‚úÖ **Reactive y declarativo**: UI se actualiza autom√°ticamente al observar Flow
- ‚úÖ **Thread-safety**: Todo manejo de threading es autom√°tico con Dispatchers
- ‚úÖ **Cancelaci√≥n estructurada**: `panelScope.cancel()` limpia todo

**Alternativa: StateFlow para datos que mantienen estado**:
```kotlin
// Si necesitas que nuevo subscriber reciba √∫ltimo valor
private val _currentFlows = MutableStateFlow<List<HttpFlowData>>(emptyList())
val currentFlows: StateFlow<List<HttpFlowData>> = _currentFlows.asStateFlow()
```

**Esfuerzo**: ~5 horas
**Prioridad**: üî¥ CR√çTICA

---

## üî¥ PROBLEMA 5: ADB Operations - Bloqueo de Android Studio

### Ubicaci√≥n
**Archivo**: `AppManager.kt:32-81, 188-235`

### Problema Actual
```kotlin
fun getInstalledApps(serialNumber: String, includeSystem: Boolean = false): List<AppInfo> {
    // Este m√©todo se ejecuta S√çNCRONAMENTE en foreground

    // 1. Ejecuta shell command (puede tomar 5-10 segundos)
    device.executeShellCommand(command, receiver, SHELL_TIMEOUT_SECONDS, TimeUnit.SECONDS)

    // 2. Por cada app, ejecuta dumpsys (10 segundos timeout √ó N apps)
    val apps = packageNames.map { packageName ->
        createAppInfo(device, packageName)  // LLAMADA S√çNCRONA ‚ö†Ô∏è
    }

    return apps
}

private fun createAppInfo(device: IDevice, packageName: String): AppInfo {
    // Ejecuta dumpsys package (toma 1-5 segundos por app)
    device.executeShellCommand(
        "dumpsys package $packageName",
        receiver,
        10,  // 10 SEGUNDOS de timeout
        TimeUnit.SECONDS
    )

    // Si hay 50 apps = 50 √ó 5 segundos = 4 MINUTOS ‚ö†Ô∏è
}
```

**Impacto**:
- Cuando usuario hace click en "Refresh Apps" ‚Üí **Android Studio se CONGELA**
- Con 50 apps instaladas = ~4 minutos de espera
- Usuario no puede hacer nada mientras tanto
- Da la impresi√≥n de que el IDE crashe√≥

### Soluci√≥n Propuesta

**Suspending Functions con Coroutines + Parallel Processing**:

```kotlin
class AppManager(project: Project) {

    private val managerScope = CoroutineScope(
        SupervisorJob() +
        Dispatchers.IO +
        CoroutineName("AppManager")
    )

    // Cache de apps por device (v√°lido por 5 minutos)
    private val appsCacheMap = ConcurrentHashMap<String, CachedAppList>()
    private val CACHE_VALIDITY_MS = 5 * 60 * 1000  // 5 minutos

    data class CachedAppList(
        val apps: List<AppInfo>,
        val timestamp: Long
    )

    /**
     * Get installed apps - suspending function.
     */
    suspend fun getInstalledAppsAsync(
        serialNumber: String,
        includeSystem: Boolean = false
    ): List<AppInfo> = withContext(Dispatchers.IO) {

        // Check cache first
        val cached = appsCacheMap[serialNumber]
        val now = System.currentTimeMillis()

        if (cached != null && (now - cached.timestamp) < CACHE_VALIDITY_MS) {
            logger.info("üì¶ Using cached app list for $serialNumber")
            return@withContext cached.apps
        }

        logger.info("üîÑ Fetching apps for $serialNumber...")

        val device = getDevice(serialNumber) ?: return@withContext emptyList()

        // Execute shell command (I/O bound, usa Dispatchers.IO)
        val receiver = EmulatorManager.CollectingOutputReceiver()
        val command = if (includeSystem) "pm list packages" else "pm list packages -3"

        device.executeShellCommand(command, receiver, 30, TimeUnit.SECONDS)

        val packageNames = receiver.output.lines()
            .filter { it.startsWith("package:") }
            .map { it.removePrefix("package:").trim() }

        logger.info("Found ${packageNames.size} packages")

        // Procesar apps EN PARALELO con async ‚≠ê
        val apps = packageNames.map { packageName ->
            async {  // Lanza coroutine paralela por cada app
                createAppInfoOptimized(device, packageName)
            }
        }.awaitAll()  // Espera a que TODAS terminen en paralelo

        // Update cache
        appsCacheMap[serialNumber] = CachedAppList(apps, now)

        logger.info("‚úÖ Fetched ${apps.size} apps successfully")

        apps
    }

    private suspend fun createAppInfoOptimized(
        device: IDevice,
        packageName: String
    ): AppInfo = withContext(Dispatchers.IO) {
        try {
            // Solo obtener UID (m√°s r√°pido que dumpsys completo)
            val uid = getAppUid(device, packageName)

            AppInfo(
                packageName = packageName,
                appName = null,
                versionName = null,
                versionCode = null,
                isSystemApp = false,
                uid = uid
            )
        } catch (e: Exception) {
            logger.debug("Failed to get details for $packageName: ${e.message}")
            AppInfo(packageName, null, null, null, false, null)
        }
    }

    fun invalidateCache(serialNumber: String) {
        appsCacheMap.remove(serialNumber)
        logger.debug("Cache invalidated for $serialNumber")
    }

    fun clearAllCaches() {
        appsCacheMap.clear()
        logger.debug("All app caches cleared")
    }
}
```

**InspectorPanel con Coroutines + Progress Flow**:

```kotlin
class InspectorPanel(private val project: Project) : JPanel(BorderLayout()) {

    private val panelScope = CoroutineScope(
        SupervisorJob() +
        Dispatchers.Default +
        CoroutineName("InspectorPanel")
    )

    private val refreshProgressLabel = JLabel("")

    private fun refreshApps() {
        val emulator = selectedEmulator ?: return

        refreshAppsButton.isEnabled = false
        refreshProgressLabel.text = "Loading..."

        // Lanzar coroutine
        panelScope.launch {
            val apps = try {
                appManager.getInstalledAppsAsync(
                    serialNumber = emulator.serialNumber,
                    includeSystem = false
                )
            } catch (e: Exception) {
                logger.error("Failed to fetch apps", e)
                emptyList()
            }

            // Actualizar UI en EDT
            withContext(Dispatchers.EDT) {
                appComboBox.removeAllItems()
                apps.forEach { app -> appComboBox.addItem(app) }

                if (apps.isNotEmpty()) {
                    appComboBox.selectedIndex = 0
                }

                refreshAppsButton.isEnabled = true
                refreshProgressLabel.text = "${apps.size} apps"

                logger.info("‚úÖ Apps refreshed: ${apps.size} found")
            }
        }
    }

    override fun removeNotify() {
        super.removeNotify()
        panelScope.cancel()  // Cleanup autom√°tico
    }
}
```

**Beneficios de Coroutines**:
- ‚úÖ **Parallelization autom√°tica**: `async {}.awaitAll()` procesa todas las apps en paralelo
- ‚úÖ **Non-blocking**: UI responsive mientras carga
- ‚úÖ **Dispatchers.IO**: Optimizado para operaciones I/O (ADB shell commands)
- ‚úÖ **Structured concurrency**: Cancelaci√≥n autom√°tica si se cierra panel
- ‚úÖ **Suspending functions**: C√≥digo secuencial que se ejecuta async
- ‚úÖ **Cancelable**: El usuario puede cerrar el panel y todo se cancela limpiamente

**Nota sobre paralelizaci√≥n**:
Con 50 apps, en lugar de 50 √ó 5seg = 250seg secuenciales, se ejecutan en paralelo:
- Tiempo total ‚âà 5-10 segundos (tiempo del m√°s lento)
- **25x m√°s r√°pido** que versi√≥n secuencial

**Esfuerzo**: ~4 horas
**Prioridad**: üî¥ CR√çTICA

---

## üü° PROBLEMA 6: Mockk Rules Matching - B√∫squeda sin √çndice

### Ubicaci√≥n
**Archivo**: `MockkRulesStore.kt:299-350`

### Problema Actual
```kotlin
fun findMatchingRuleObject(method: String, host: String, path: String, queryParams: Map<String, String>): MockkRule? {
    // Itera sobre TODAS las reglas en CADA request ‚ö†Ô∏è
    for ((index, rule) in rules.withIndex()) {
        if (!rule.enabled) continue

        val ruleCollection = collections[rule.collectionId]
        if (ruleCollection == null || !ruleCollection.enabled) continue

        // Match method
        if (!rule.method.equals(method, ignoreCase = true)) continue

        // Evaluate match (incluye regex evaluation)
        val matches = matchesStructuredQuiet(rule, host, path, queryParams)

        if (matches) return rule
    }

    return null
}
```

**Impacto**:
- Con 100 reglas + 100 requests/segundo = 10,000 iteraciones/segundo
- Evaluaci√≥n de regex en cada iteraci√≥n
- Complejidad O(n) donde n = n√∫mero de reglas
- Sin caching de resultados

### Soluci√≥n Propuesta

**Implementar Index Multi-Level + Caching**:

```kotlin
class MockkRulesStore(project: Project) : PersistentStateComponent<MockkRulesStore.State> {

    // √çndice por m√©todo + host para lookup r√°pido
    private val ruleIndex = ConcurrentHashMap<String, MutableList<MockkRule>>()

    // Cache de matches recientes (evitar re-evaluar mismas URLs)
    private val matchCache = object : LinkedHashMap<String, MockkRule?>(100, 0.75f, true) {
        override fun removeEldestEntry(eldest: MutableMap.MutableEntry<String, MockkRule?>?): Boolean {
            return size > 100  // Mantener solo √∫ltimos 100 matches
        }
    }

    /**
     * Add rule and update index.
     */
    fun addRule(/* ... */): MockkRule {
        val rule = MockkRule(/* ... */)
        rules.add(rule)

        // Update index
        updateIndexForRule(rule)

        // Invalidate cache
        matchCache.clear()

        logger.info("‚ûï Added mock rule: $name to collection: $collectionId")
        ruleAddedListeners.forEach { it(rule) }

        return rule
    }

    /**
     * Remove rule and update index.
     */
    fun removeRule(rule: MockkRule) {
        if (rules.remove(rule)) {
            removeFromIndex(rule)
            matchCache.clear()
            logger.info("‚ûñ Removed mock rule: ${rule.name}")
            ruleRemovedListeners.forEach { it(rule) }
        }
    }

    /**
     * Build/rebuild complete index.
     */
    private fun rebuildIndex() {
        ruleIndex.clear()
        rules.forEach { rule ->
            updateIndexForRule(rule)
        }
        logger.debug("üî® Rebuilt rule index: ${ruleIndex.size} entries")
    }

    /**
     * Add rule to index.
     */
    private fun updateIndexForRule(rule: MockkRule) {
        val key = buildIndexKey(rule.method, rule.host)
        ruleIndex.getOrPut(key) { mutableListOf() }.add(rule)
    }

    /**
     * Remove rule from index.
     */
    private fun removeFromIndex(rule: MockkRule) {
        val key = buildIndexKey(rule.method, rule.host)
        ruleIndex[key]?.remove(rule)
    }

    /**
     * Build index key from method and host.
     */
    private fun buildIndexKey(method: String, host: String): String {
        return "${method.uppercase()}:${host.lowercase()}"
    }

    /**
     * Find matching rule using index - OPTIMIZED.
     */
    fun findMatchingRuleObject(
        method: String,
        host: String,
        path: String,
        queryParams: Map<String, String>
    ): MockkRule? {
        // Check cache first
        val cacheKey = "$method:$host:$path:${queryParams.hashCode()}"
        val cached = matchCache[cacheKey]
        if (cached != null) {
            logger.debug("‚úÖ Cache hit for $cacheKey")
            return cached
        }

        logger.debug("üîç Looking for match:")
        logger.debug("   Method: $method, Host: $host, Path: $path")

        // Get enabled collections
        val enabledCollections = collections.values.filter { it.enabled }
        if (enabledCollections.isEmpty()) {
            logger.debug("‚ö†Ô∏è No enabled collections")
            return null
        }

        // Use index to get candidate rules (only rules matching method:host)
        val indexKey = buildIndexKey(method, host)
        val candidateRules = ruleIndex[indexKey] ?: emptyList()

        logger.debug("üìã Index lookup: found ${candidateRules.size} candidate rules for $indexKey")

        // Iterate only over candidate rules (much smaller set)
        for (rule in candidateRules) {
            // Skip if rule not enabled
            if (!rule.enabled) continue

            // Skip if collection disabled
            val ruleCollection = collections[rule.collectionId]
            if (ruleCollection == null || !ruleCollection.enabled) continue

            // Match path and query params
            val matches = matchesStructuredQuiet(rule, host, path, queryParams)

            if (matches) {
                logger.debug("‚úÖ MATCHED: ${rule.name}")

                // Cache result
                matchCache[cacheKey] = rule

                return rule
            }
        }

        logger.debug("‚ùå No matching rule found (checked ${candidateRules.size} candidates)")

        // Cache negative result too
        matchCache[cacheKey] = null

        return null
    }

    /**
     * Pre-compile regex patterns for faster matching.
     */
    data class MockkRule(
        // ... existing fields ...

        // Cached compiled regex patterns
        @Transient
        var compiledPathPattern: Regex? = null,
        @Transient
        var compiledQueryPatterns: Map<String, Regex>? = null
    ) {
        /**
         * Pre-compile regex patterns for this rule.
         */
        fun compilePatterns() {
            // Compile path regex if needed
            if (path.contains(".*") || path.contains("+") || path.contains("?")) {
                compiledPathPattern = try {
                    Regex(path)
                } catch (e: Exception) {
                    null
                }
            }

            // Compile query param regex patterns
            val regexParams = queryParams.filter { it.matchType == MatchType.REGEX }
            if (regexParams.isNotEmpty()) {
                compiledQueryPatterns = regexParams.associate { param ->
                    param.key to try {
                        Regex(param.value)
                    } catch (e: Exception) {
                        Regex(".*")  // Fallback
                    }
                }
            }
        }
    }

    override fun loadState(state: State) {
        collections.clear()
        rules.clear()

        // Load collections
        state.collections.forEach { collection ->
            collections[collection.id] = collection
        }

        // Load rules
        rules.addAll(state.rules)

        // Pre-compile regex patterns
        rules.forEach { it.compilePatterns() }

        // Build index
        rebuildIndex()

        // Migrate old rules
        migrateOldRulesToDefaultCollection()

        logger.info("üìö Loaded ${collections.size} collection(s) and ${rules.size} mock rule(s) from storage")
    }
}
```

**Optimizar evaluaci√≥n de match con patterns pre-compilados**:

```kotlin
private fun matchesStructuredQuiet(rule: MockkRule, host: String, path: String, queryParams: Map<String, String>): Boolean {
    // 1. Match host (case-insensitive)
    if (!rule.host.equals(host, ignoreCase = true)) {
        return false
    }

    // 2. Match path (usar regex pre-compilado si existe)
    if (rule.compiledPathPattern != null) {
        if (!rule.compiledPathPattern!!.matches(path)) {
            return false
        }
    } else {
        // Exact match
        if (rule.path != path) {
            return false
        }
    }

    // 3. Match query params
    for (ruleParam in rule.queryParams) {
        if (ruleParam.required) {
            val actualValue = queryParams[ruleParam.key]
            if (actualValue == null) {
                return false
            }

            // Check value based on match type
            when (ruleParam.matchType) {
                MatchType.EXACT -> {
                    if (ruleParam.value != actualValue) {
                        return false
                    }
                }
                MatchType.WILDCARD -> {
                    // Accept any value
                }
                MatchType.REGEX -> {
                    // Use pre-compiled pattern
                    val pattern = rule.compiledQueryPatterns?.get(ruleParam.key)
                    if (pattern != null && !pattern.matches(actualValue)) {
                        return false
                    } else if (pattern == null) {
                        // Fallback to runtime compilation
                        try {
                            if (!Regex(ruleParam.value).matches(actualValue)) {
                                return false
                            }
                        } catch (_: Exception) {
                            return false
                        }
                    }
                }
            }
        }
    }

    return true
}
```

**Beneficios**:
- ‚úÖ B√∫squeda O(1) en lugar de O(n) con √≠ndice
- ‚úÖ Cache reduce evaluaciones repetidas
- ‚úÖ Regex pre-compilados m√°s r√°pidos
- ‚úÖ Maneja 1000s de reglas sin degradaci√≥n

**Esfuerzo**: ~4 horas
**Prioridad**: üü° ALTA (no cr√≠tica pero importante)

---

## üü° PROBLEMA 7: Logging Excesivo

### Ubicaci√≥n
**Archivo**: `MockkHttpLogger.kt:136`, `GlobalOkHttpInterceptorServer.kt`

### Problema Actual
- Cada request genera 5-10 l√≠neas de log
- 100 requests/segundo = 500-1000 l√≠neas de log/segundo
- Logger mantiene 1000 entries en memoria
- Listeners invocados en cada log entry
- Log Panel UI se actualiza constantemente

### Soluci√≥n Propuesta

**Implementar Log Levels + Conditional Logging + Sampling**:

```kotlin
class MockkHttpLogger {

    // Configuraci√≥n de niveles
    enum class LogLevel(val priority: Int) {
        DEBUG(0),
        INFO(1),
        WARN(2),
        ERROR(3)
    }

    companion object {
        // Nivel m√≠nimo para loggear (configurable en settings)
        @Volatile
        var minimumLevel: LogLevel = LogLevel.INFO  // Solo INFO, WARN, ERROR por defecto

        // L√≠mite de entries en memoria
        private const val MAX_LOG_ENTRIES = 500  // Reducir de 1000 a 500

        // Sampling: solo loggear 1 de cada N requests en DEBUG
        private const val DEBUG_SAMPLE_RATE = 10  // Solo 1 de cada 10 requests
        @Volatile
        private var debugSampleCounter = 0
    }

    fun debug(message: String) {
        // Skip si nivel es m√°s alto que DEBUG
        if (minimumLevel.priority > LogLevel.DEBUG.priority) {
            return
        }

        // Sampling para reducir volumen
        debugSampleCounter++
        if (debugSampleCounter % DEBUG_SAMPLE_RATE != 0) {
            return  // Skip este log
        }

        log(LogLevel.DEBUG, message)
        platformLogger.debug(message)
    }

    fun info(message: String) {
        if (minimumLevel.priority > LogLevel.INFO.priority) {
            return
        }
        log(LogLevel.INFO, message)
        platformLogger.info(message)
    }

    private fun log(level: LogLevel, message: String, throwable: Throwable? = null) {
        val entry = LogEntry(
            timestamp = getCurrentTimestamp(),
            level = level,
            message = message,
            throwable = throwable
        )

        logEntries.add(entry)

        // Limit log entries (reducido a 500)
        if (logEntries.size > MAX_LOG_ENTRIES) {
            // Remover los primeros 100 entries para hacer espacio
            repeat(100) {
                if (logEntries.isNotEmpty()) {
                    logEntries.removeAt(0)
                }
            }
        }

        notifyListeners(entry)
    }

    private fun notifyListeners(entry: LogEntry) {
        // Solo notificar si hay listeners registrados
        if (listeners.isEmpty()) {
            return
        }

        ApplicationManager.getApplication().invokeLater {
            listeners.forEach { it.onLogAdded(entry) }
        }
    }
}
```

**Reducir logging verboso en GlobalServer**:

```kotlin
class GlobalOkHttpInterceptorServer {

    private fun handleClient(socket: Socket) {
        socket.use { clientSocket ->
            try {
                // ... c√≥digo existente ...

                // ANTES: 5 l√≠neas de log por request
                // logger.info("üî¥ INTERCEPTED: ${flowData.request.method} ${flowData.request.url}")
                // logger.info("   üì¶ Package: ${flowData.packageName ?: "unknown"}")
                // logger.info("   üéØ Project hint: ${flowData.projectId ?: "none"}")
                // ...

                // DESPU√âS: 1 l√≠nea concisa solo en DEBUG
                logger.debug("${flowData.request.method} ${flowData.request.url} -> ${targetProject?.projectName ?: "no project"}")

                // Route flow to appropriate project(s)
                val response = routeFlow(flowData)

                val responseJson = gson.toJson(response)
                writer.println(responseJson)

                // logger.debug("‚úÖ Response sent")  // ELIMINAR - demasiado verboso

            } catch (e: Exception) {
                logger.error("Error handling client", e)  // Solo errores
            }
        }
    }
}
```

**Agregar UI Setting para controlar Log Level**:

```kotlin
// En Settings/Preferences panel
class MockkHttpSettingsPanel : JPanel() {
    private val logLevelComboBox = ComboBox(arrayOf(
        "DEBUG (verbose)",
        "INFO (default)",
        "WARN (minimal)",
        "ERROR (only errors)"
    ))

    fun apply() {
        val selectedLevel = when (logLevelComboBox.selectedIndex) {
            0 -> MockkHttpLogger.LogLevel.DEBUG
            1 -> MockkHttpLogger.LogLevel.INFO
            2 -> MockkHttpLogger.LogLevel.WARN
            3 -> MockkHttpLogger.LogLevel.ERROR
            else -> MockkHttpLogger.LogLevel.INFO
        }

        MockkHttpLogger.minimumLevel = selectedLevel
    }
}
```

**Beneficios**:
- ‚úÖ Reduce logging en 90% (con INFO level)
- ‚úÖ Menor presi√≥n en memoria y UI
- ‚úÖ Usuario puede activar DEBUG cuando necesita troubleshooting
- ‚úÖ Sampling evita spam en logs

**Esfuerzo**: ~2 horas
**Prioridad**: üü° MEDIA

---

## üü° PROBLEMA 8: Android Interceptor - Thread Creation sin Pool

### Ubicaci√≥n
**Archivo**: `MockkHttpInterceptor.kt:266-283`

### Problema Actual
```kotlin
private fun sendToPluginAsync(
    request: Request,
    response: Response,
    duration: Long
) {
    Thread {  // Crea thread nuevo por CADA request async ‚ö†Ô∏è
        try {
            val socket = Socket(pluginHost, pluginPort)
            // ...
        } catch (e: Exception) {
            Log.e(TAG, "Error sending flow async", e)
        }
    }.start()
}
```

**Impacto**:
- En Recording Mode (sin debug), cada request crea un thread
- 100 requests = 100 threads creados en la app Android
- Consume recursos de la app
- No hay l√≠mite ni reuso de threads

### Soluci√≥n Propuesta

**Usar Kotlin Coroutines en Android Interceptor**:

```kotlin
class MockkHttpInterceptor @JvmOverloads constructor(
    context: Context? = null,
    private val pluginHost: String = "10.0.2.2",
    private val pluginPort: Int = 9876
) : Interceptor {

    companion object {
        private const val TAG = "MockkHttpInterceptor"

        // CoroutineScope para async operations (compartido)
        private val asyncScope = CoroutineScope(
            SupervisorJob() +
            Dispatchers.IO +
            CoroutineName("MockkHttp-Android-Async")
        )

        // Semaphore para limitar concurrencia
        private val sendSemaphore = Semaphore(5)  // M√°ximo 5 env√≠os concurrentes
        private val pendingCount = AtomicInteger(0)
        private const val MAX_PENDING = 100
    }

    private fun sendToPluginAsync(
        request: Request,
        response: Response,
        duration: Long
    ) {
        // Check if queue is full
        if (pendingCount.get() >= MAX_PENDING) {
            Log.w(TAG, "‚ö†Ô∏è Async queue full, skipping flow: ${request.url}")
            return
        }

        // Launch coroutine for async sending
        asyncScope.launch {
            pendingCount.incrementAndGet()

            try {
                // Acquire semaphore (limita a 5 concurrent sends)
                sendSemaphore.withPermit {
                    sendFlowToPlugin(request, response, duration)
                }
            } catch (e: Exception) {
                Log.e(TAG, "Error sending flow async", e)
            } finally {
                pendingCount.decrementAndGet()
            }
        }
    }

    /**
     * Send flow to plugin - suspending function.
     */
    private suspend fun sendFlowToPlugin(
        request: Request,
        response: Response,
        duration: Long
    ) = withContext(Dispatchers.IO) {
        try {
            val socket = Socket(pluginHost, pluginPort)
            socket.soTimeout = CONNECTION_TIMEOUT_MS

            socket.use {
                val flowData = serializeFlow(request, response, duration)
                val json = gson.toJson(flowData) + "\n"

                it.getOutputStream().write(json.toByteArray())
                it.getOutputStream().flush()

                Log.d(TAG, "Sent flow to plugin (async): ${request.method} ${request.url}")
            }
        } catch (e: Exception) {
            Log.w(TAG, "Failed to send flow to plugin: ${e.message}")
        }
    }
}
```

**Extensi√≥n para Semaphore.withPermit()** (si no est√° disponible):

```kotlin
// Agregar en archivo utils
suspend inline fun <T> Semaphore.withPermit(action: () -> T): T {
    acquire()
    try {
        return action()
    } finally {
        release()
    }
}
```

**Beneficios de Coroutines en Android**:
- ‚úÖ **Lightweight**: 100 coroutines ‚âà 10KB vs 5 threads ‚âà 5MB
- ‚úÖ **Semaphore**: Control de concurrencia m√°s elegante que ExecutorService
- ‚úÖ **Dispatchers.IO**: Pool optimizado para I/O operations
- ‚úÖ **Non-blocking**: Socket I/O no bloquea threads
- ‚úÖ **Structured concurrency**: Scope compartido, f√°cil de cancelar
- ‚úÖ **Backpressure**: L√≠mite de pending + semaphore

**Nota**: Coroutines ya est√° disponible en Android (parte de Kotlin stdlib), no requiere dependencia adicional en apps modernas.

**Esfuerzo**: ~1.5 horas
**Prioridad**: üü° MEDIA

---

## üî¥ PROBLEMA 9: MockkHttpInterceptor - Hot Path Optimizations (Android)

### Ubicaci√≥n
**Archivo**: `android-library/src/main/kotlin/.../MockkHttpInterceptor.kt`

### Contexto
El interceptor de Android es el **punto de entrada** de todas las requests HTTP de la app. Cualquier ineficiencia aqu√≠ se multiplica por el n√∫mero de requests, causando:
- Latencia adicional en todas las requests HTTP
- Consumo excesivo de memoria y CPU en la app
- Degradaci√≥n de experiencia de usuario

### Sub-problema 9.1: BuildConfig Reflection en Hot Path ‚ö†Ô∏è **CR√çTICO**

#### Ubicaci√≥n
**L√≠neas**: 90-104

#### Problema Actual
```kotlin
override fun intercept(chain: Interceptor.Chain): Response {
    // SECURITY: Double-check we're not in a release build
    try {
        val buildConfigClass = Class.forName("${appContext?.packageName}.BuildConfig")
        val debugField = buildConfigClass.getDeclaredField("DEBUG")
        val isDebugBuild = debugField.getBoolean(null)

        if (!isDebugBuild) {
            Log.e(TAG, "‚ùå SECURITY: MockkHttpInterceptor in RELEASE build!")
            return chain.proceed(chain.request())
        }
    } catch (e: Exception) {
        Log.w(TAG, "Could not determine build type, assuming debug: ${e.message}")
    }
    // ... resto del intercept
}
```

**Impacto**:
- Esta reflection se ejecuta **EN CADA REQUEST HTTP** (hot path) ‚ö†Ô∏è
- Reflection es muy costoso: `Class.forName()` + `getDeclaredField()` + `getBoolean()`
- Overhead: **1-5ms por request**
- Con 100 requests/segundo = **100-500ms de CPU** puro desperdiciado
- Con 1000 requests = **5 segundos de CPU** solo verificando build type

#### Soluci√≥n Propuesta

```kotlin
class MockkHttpInterceptor @JvmOverloads constructor(
    context: Context? = null,
    private val pluginHost: String = "10.0.2.2",
    private val pluginPort: Int = 9876
) : Interceptor {

    companion object {
        private const val TAG = "MockkHttpInterceptor"

        // Cache del build type check (Double-Checked Locking)
        @Volatile
        private var isDebugBuildCached: Boolean? = null

        /**
         * Check if running in debug build.
         * Cached after first check to avoid repeated reflection.
         */
        private fun isDebugBuild(context: Context?): Boolean {
            // Fast path: check cache
            isDebugBuildCached?.let { return it }

            // Slow path: perform reflection once
            synchronized(this) {
                // Double-check after acquiring lock
                isDebugBuildCached?.let { return it }

                val result = try {
                    val buildConfigClass = Class.forName("${context?.packageName}.BuildConfig")
                    val debugField = buildConfigClass.getDeclaredField("DEBUG")
                    debugField.getBoolean(null)
                } catch (e: Exception) {
                    Log.w(TAG, "Could not determine build type, assuming debug: ${e.message}")
                    true  // Fail-safe: assume debug
                }

                isDebugBuildCached = result
                Log.i(TAG, "Build type cached: ${if (result) "DEBUG" else "RELEASE"}")

                return result
            }
        }
    }

    override fun intercept(chain: Interceptor.Chain): Response {
        // SECURITY: Check cached build type (fast: ~0.01ms)
        if (!isDebugBuild(appContext)) {
            Log.e(TAG, "‚ùå SECURITY: MockkHttpInterceptor in RELEASE build!")
            return chain.proceed(chain.request())
        }

        // ... resto del intercept
    }
}
```

**Beneficios**:
- ‚úÖ Reflection solo se ejecuta **UNA VEZ** al inicio
- ‚úÖ Checks subsiguientes son **cache hit**: ~0.01ms
- ‚úÖ Reduce overhead de **1-5ms ‚Üí 0.01ms** por request
- ‚úÖ Con 100 requests/segundo: ahorra **100-500ms de CPU**
- ‚úÖ Thread-safe con Double-Checked Locking

**Esfuerzo**: ~1 hora
**Prioridad**: üî¥ CR√çTICA

---

### Sub-problema 9.2: Socket Creation Sin Pool ‚ö†Ô∏è **CR√çTICO**

#### Ubicaci√≥n
**L√≠neas**: 175, 217, 268

#### Problema Actual
```kotlin
// Ping (l√≠nea 175)
Socket(pluginHost, pluginPort).use { socket ->
    socket.soTimeout = PING_TIMEOUT_MS
    // ...
}

// Debug mode (l√≠nea 217)
val socket = Socket(pluginHost, pluginPort)
socket.soTimeout = READ_TIMEOUT_MS
socket.use { /* ... */ }

// Recording mode (l√≠nea 268)
Thread {
    val socket = Socket(pluginHost, pluginPort)
    socket.soTimeout = CONNECTION_TIMEOUT_MS
    socket.use { /* ... */ }
}.start()
```

**Impacto**:
- Crea socket **TCP NUEVO** en cada operaci√≥n
- TCP handshake overhead: **10-50ms por socket** (SYN, SYN-ACK, ACK)
- Con 100 requests/segundo = **100 sockets nuevos** = **1-5 segundos** de overhead
- No reutiliza conexiones (sin keep-alive)
- Agota file descriptors con alto volumen

#### Soluci√≥n Propuesta

```kotlin
companion object {
    /**
     * Socket pool para reutilizar conexiones.
     */
    private object SocketPool {
        private val available = ConcurrentLinkedQueue<PooledSocket>()
        private const val MAX_POOL_SIZE = 5
        private const val SOCKET_MAX_AGE_MS = 30_000  // 30 segundos

        data class PooledSocket(
            val socket: Socket,
            val createdAt: Long = System.currentTimeMillis()
        ) {
            fun isStale(): Boolean {
                return System.currentTimeMillis() - createdAt > SOCKET_MAX_AGE_MS
            }

            fun isUsable(): Boolean {
                return !isStale() &&
                       socket.isConnected &&
                       !socket.isClosed &&
                       !socket.isInputShutdown &&
                       !socket.isOutputShutdown
            }
        }

        fun acquire(): Socket? {
            // Try to reuse existing socket
            while (true) {
                val pooled = available.poll() ?: break

                if (pooled.isUsable()) {
                    Log.v(TAG, "‚ôªÔ∏è Reusing pooled socket")
                    return pooled.socket
                } else {
                    // Socket is stale or closed, discard
                    try {
                        pooled.socket.close()
                    } catch (e: Exception) {
                        // Ignore
                    }
                }
            }

            // Create new socket if pool is empty
            return try {
                Log.v(TAG, "üîå Creating new socket")
                Socket().apply {
                    keepAlive = true  // Enable TCP keep-alive
                    tcpNoDelay = true  // Disable Nagle's algorithm for lower latency
                    connect(InetSocketAddress(pluginHost, pluginPort), CONNECTION_TIMEOUT_MS)
                }
            } catch (e: Exception) {
                Log.e(TAG, "Failed to create socket", e)
                null
            }
        }

        fun release(socket: Socket?) {
            socket?.let {
                try {
                    if (available.size < MAX_POOL_SIZE &&
                        it.isConnected &&
                        !it.isClosed) {

                        val pooled = PooledSocket(it)
                        if (pooled.isUsable()) {
                            available.offer(pooled)
                            Log.v(TAG, "üíæ Socket returned to pool (size: ${available.size})")
                            return
                        }
                    }

                    // Pool full or socket not usable, close it
                    it.close()
                } catch (e: Exception) {
                    Log.e(TAG, "Error releasing socket", e)
                }
            }
        }

        fun clear() {
            while (true) {
                val pooled = available.poll() ?: break
                try {
                    pooled.socket.close()
                } catch (e: Exception) {
                    // Ignore
                }
            }
        }
    }
}

// Usar el pool en todas las operaciones
private fun isPluginConnected(): Boolean {
    // ... cache checks ...

    val connected = try {
        val socket = SocketPool.acquire() ?: return false

        try {
            socket.soTimeout = PING_TIMEOUT_MS
            socket.getOutputStream().write("PING\n".toByteArray())
            socket.getOutputStream().flush()

            val response = ByteArray(4)
            val read = socket.getInputStream().read(response)
            val success = read > 0 && String(response, 0, read).startsWith("PONG")

            if (success) {
                SocketPool.release(socket)  // Return to pool
            } else {
                socket.close()  // Don't reuse on error
            }

            success
        } catch (e: Exception) {
            socket.close()  // Don't reuse on error
            throw e
        }
    } catch (e: Exception) {
        Log.d(TAG, "‚ö†Ô∏è Plugin not reachable: ${e.message}")
        false
    }

    // ...
}

// Similar pattern for sendToPluginAndWait() and sendToPluginAsync()
```

**Beneficios**:
- ‚úÖ Reutiliza sockets con **TCP keep-alive**
- ‚úÖ Reduce overhead de **10-50ms ‚Üí ~1ms** por request
- ‚úÖ Con 100 requests/segundo: ahorra **1-5 segundos**
- ‚úÖ Reduce file descriptors de 100 ‚Üí 5
- ‚úÖ Pool bounded evita leak de sockets

**Esfuerzo**: ~3 horas
**Prioridad**: üî¥ CR√çTICA

---

### Sub-problema 9.3: peekBody() para Responses Grandes ‚ö†Ô∏è **CR√çTICO**

#### Ubicaci√≥n
**L√≠neas**: 305-322

#### Problema Actual
```kotlin
val responseBodyString = try {
    val contentLength = response.body?.contentLength() ?: 0
    val maxSize = if (contentLength > 0) {
        minOf(contentLength, 5 * 1024 * 1024)  // Max 5MB ‚ö†Ô∏è
    } else {
        5 * 1024 * 1024  // Default 5MB ‚ö†Ô∏è
    }

    Log.d(TAG, "üìñ Reading response body: contentLength=$contentLength, maxSize=$maxSize")
    val body = response.peekBody(maxSize).string()  // Lee hasta 5MB en CADA request
    Log.d(TAG, "‚úÖ Read ${body.length} chars from response body")
    body
} catch (e: Exception) {
    Log.w(TAG, "‚ö†Ô∏è Failed to read response body", e)
    ""
}
```

**Impacto**:
- `peekBody(5MB)` lee **hasta 5MB** en memoria por cada response
- Para im√°genes/videos/PDFs es **MUY lento**: 100-500ms
- Con 10 requests de im√°genes simult√°neas = **50MB de memoria**
- Puede causar **OutOfMemoryError** en apps con alto tr√°fico
- Innecesario: El plugin NO necesita el body completo de una imagen de 5MB

#### Soluci√≥n Propuesta

```kotlin
private fun serializeFlow(
    request: Request,
    response: Response,
    duration: Long
): FlowData {
    val responseBodyString = try {
        val contentType = response.body?.contentType()?.toString() ?: ""
        val contentLength = response.body?.contentLength() ?: 0

        // Skip body for binary content or large responses
        when {
            // Binary content: skip body
            contentType.contains("image/", ignoreCase = true) ||
            contentType.contains("video/", ignoreCase = true) ||
            contentType.contains("audio/", ignoreCase = true) ||
            contentType.contains("application/pdf", ignoreCase = true) ||
            contentType.contains("application/zip", ignoreCase = true) ||
            contentType.contains("application/octet-stream", ignoreCase = true) -> {
                Log.d(TAG, "üì∑ Skipping binary response body (${contentType}, ${formatBytes(contentLength)})")
                "[Binary content: $contentType, ${formatBytes(contentLength)}]"
            }

            // Large text responses: truncate
            contentLength > 100_000 -> {  // 100KB limit for text
                Log.d(TAG, "üì¶ Truncating large response (${formatBytes(contentLength)})")
                val body = response.peekBody(100_000).string()
                "$body\n\n... [Truncated: total ${formatBytes(contentLength)}]"
            }

            // Normal text response: read with reasonable limit
            else -> {
                val maxSize = if (contentLength > 0) {
                    minOf(contentLength, 1 * 1024 * 1024)  // Max 1MB (not 5MB)
                } else {
                    100_000  // Default 100KB (not 5MB)
                }

                response.peekBody(maxSize).string()
            }
        }
    } catch (e: Exception) {
        Log.w(TAG, "‚ö†Ô∏è Failed to read response body", e)
        ""
    }

    // ...
}

private fun formatBytes(bytes: Long): String {
    return when {
        bytes >= 1024 * 1024 -> "%.2f MB".format(bytes / (1024.0 * 1024.0))
        bytes >= 1024 -> "%.2f KB".format(bytes / 1024.0)
        else -> "$bytes bytes"
    }
}
```

**Beneficios**:
- ‚úÖ Reduce memoria de **5MB ‚Üí 100KB** por request (50x menos)
- ‚úÖ Reduce latencia de **100-500ms ‚Üí 5-10ms** para im√°genes
- ‚úÖ Previene **OutOfMemoryError** con alto tr√°fico
- ‚úÖ Mantiene funcionalidad para responses de texto (JSON, HTML, etc.)
- ‚úÖ Mejora experiencia: la app no se ralentiza al capturar tr√°fico

**Esfuerzo**: ~2 horas
**Prioridad**: üî¥ CR√çTICA

---

### Sub-problema 9.4: No Batching en Recording Mode ‚ö†Ô∏è **IMPORTANTE**

#### Ubicaci√≥n
**L√≠neas**: 266-282

#### Problema Actual
```kotlin
private fun sendToPluginAsync(
    request: Request,
    response: Response,
    duration: Long
) {
    Thread {  // Un thread NUEVO por request ‚ö†Ô∏è
        try {
            val socket = Socket(pluginHost, pluginPort)  // Un socket NUEVO ‚ö†Ô∏è
            socket.soTimeout = CONNECTION_TIMEOUT_MS

            socket.use {
                val flowData = serializeFlow(request, response, duration)
                val json = gson.toJson(flowData) + "\n"
                it.getOutputStream().write(json.toByteArray())
                it.getOutputStream().flush()

                Log.d(TAG, "Sent flow to plugin (async): ${request.method} ${request.url}")
            }
        } catch (e: Exception) {
            Log.e(TAG, "Error sending flow async", e)
        }
    }.start()  // Lanza thread ‚ö†Ô∏è
}
```

**Impacto**:
- En Recording mode, **cada request HTTP** crea:
  - 1 thread nuevo
  - 1 socket TCP nuevo
  - 1 serializaci√≥n Gson
- Con 100 requests/segundo = **100 threads + 100 sockets** = Sobrecarga masiva
- Threads consumen stack memory (~1MB cada uno)
- Context switching reduce performance general de la app

#### Soluci√≥n Propuesta (con Coroutines)

```kotlin
companion object {
    // Ya incluido en Problema #8 del documento principal
    // CoroutineScope para async operations
    private val asyncScope = CoroutineScope(
        SupervisorJob() +
        Dispatchers.IO +
        CoroutineName("MockkHttp-Android-Async")
    )

    // Channel para batching
    private val asyncChannel = Channel<FlowData>(capacity = 500)
    private var batchSenderStarted = false

    private fun startBatchSender() {
        if (batchSenderStarted) return

        synchronized(this) {
            if (batchSenderStarted) return
            batchSenderStarted = true

            // Batch sender coroutine
            asyncScope.launch {
                while (true) {
                    try {
                        // Collect batch (wait up to 500ms or 50 items)
                        val batch = mutableListOf<FlowData>()

                        // Wait for first item (blocking)
                        val first = withTimeoutOrNull(500) {
                            asyncChannel.receive()
                        } ?: continue

                        batch.add(first)

                        // Collect additional items (non-blocking)
                        repeat(49) {
                            val item = asyncChannel.tryReceive().getOrNull() ?: return@repeat
                            batch.add(item)
                        }

                        // Send batch
                        sendBatch(batch)

                    } catch (e: CancellationException) {
                        break
                    } catch (e: Exception) {
                        Log.e(TAG, "Error in batch sender", e)
                    }
                }
            }
        }
    }

    private suspend fun sendBatch(batch: List<FlowData>) {
        withContext(Dispatchers.IO) {
            try {
                val socket = SocketPool.acquire() ?: return@withContext

                try {
                    socket.soTimeout = CONNECTION_TIMEOUT_MS
                    val writer = socket.getOutputStream().bufferedWriter()

                    batch.forEach { flowData ->
                        val json = gson.toJson(flowData)
                        writer.write(json)
                        writer.write("\n")
                    }

                    writer.flush()
                    Log.d(TAG, "üì¶ Sent batch of ${batch.size} flows")

                    SocketPool.release(socket)
                } catch (e: Exception) {
                    socket.close()
                    throw e
                }
            } catch (e: Exception) {
                Log.e(TAG, "Error sending batch", e)
            }
        }
    }
}

private fun sendToPluginAsync(
    request: Request,
    response: Response,
    duration: Long
) {
    startBatchSender()

    val flowData = serializeFlow(request, response, duration)

    // Offer to channel (non-blocking)
    val offered = asyncChannel.trySend(flowData).isSuccess
    if (!offered) {
        Log.w(TAG, "‚ö†Ô∏è Async channel full, dropping flow")
    }
}
```

**Beneficios**:
- ‚úÖ Reduce de **100 threads ‚Üí 1 coroutine** workers
- ‚úÖ Reduce de **100 sockets ‚Üí 2-3 sockets** reutilizados
- ‚úÖ Batching: env√≠a hasta 50 flows en un solo socket
- ‚úÖ Non-blocking: no bloquea threads de OkHttp
- ‚úÖ Backpressure: channel con capacidad limitada

**Esfuerzo**: ~4 horas (ya cubierto en Problema #8, aplicar aqu√≠)
**Prioridad**: üü° ALTA (importante pero ya cubierto)

---

### Sub-problema 9.5: Headers.toMap() en Hot Path ‚ö†Ô∏è **MODERADO**

#### Ubicaci√≥n
**L√≠neas**: 329, 334, 405-409

#### Problema Actual
```kotlin
return FlowData(
    // ...
    request = RequestData(
        // ...
        headers = request.headers.toMap(),  // Crea HashMap nuevo ‚ö†Ô∏è
        // ...
    ),
    response = ResponseData(
        // ...
        headers = response.headers.toMap(),  // Crea HashMap nuevo ‚ö†Ô∏è
        // ...
    ),
    // ...
)

// Extension function
private fun Headers.toMap(): Map<String, String> {
    return names().associateWith { name ->  // Allocates HashMap
        get(name) ?: ""
    }
}
```

**Impacto**:
- Se llama **2 veces por request** (request headers + response headers)
- Crea HashMap nuevo cada vez (allocation)
- Con headers grandes (10-20 headers) puede ser costoso
- Overhead: ~0.5ms por request

#### Soluci√≥n Propuesta

```kotlin
/**
 * Convert OkHttp Headers to Map with pre-sized HashMap.
 */
private fun Headers.toMap(): Map<String, String> {
    if (size() == 0) return emptyMap()  // Fast path for empty headers

    // Pre-size HashMap to exact size (avoids resizing)
    val map = HashMap<String, String>(size())
    names().forEach { name ->
        map[name] = get(name) ?: ""
    }
    return map
}
```

**Beneficios**:
- ‚úÖ Pre-sized HashMap evita resizing interno
- ‚úÖ Fast path para headers vac√≠os
- ‚úÖ Mejora ~0.5ms por request
- ‚úÖ Menor presi√≥n en GC

**Esfuerzo**: ~0.5 horas
**Prioridad**: üü¢ BAJA (optimizaci√≥n menor pero f√°cil)

---

### Sub-problema 9.6: failedAttempts Sin Reset ‚ö†Ô∏è **BUG**

#### Ubicaci√≥n
**L√≠neas**: 68, 161-164, 195

#### Problema Actual
```kotlin
companion object {
    @Volatile
    private var failedAttempts: Int = 0
    private const val MAX_FAILED_ATTEMPTS = 3
}

private fun isPluginConnected(): Boolean {
    // If we've failed too many times, stop trying (failsafe mode)
    if (failedAttempts >= MAX_FAILED_ATTEMPTS) {
        Log.d(TAG, "‚ö†Ô∏è Plugin connection disabled (failsafe mode)")
        return false  // STUCK FOREVER ‚ö†Ô∏è
    }

    // ... ping logic ...

    catch (e: Exception) {
        Log.d(TAG, "‚ö†Ô∏è Plugin not reachable: ${e.message}")
        failedAttempts++  // Increments on failure
        // But NEVER resets except on successful ping (line 186)
        Log.d(TAG, "Failed attempts: $failedAttempts / $MAX_FAILED_ATTEMPTS")
        false
    }

    // ...
}
```

**Impacto**:
- Si plugin se desconecta temporalmente, `failedAttempts` llega a 3
- Interceptor entra en "failsafe mode" **PERMANENTEMENTE**
- Incluso si el usuario reinicia el plugin, el interceptor NO se recupera
- Usuario tiene que **reiniciar la app** para volver a conectar
- Es un **BUG cr√≠tico de UX**

#### Soluci√≥n Propuesta

```kotlin
companion object {
    @Volatile
    private var failedAttempts: Int = 0
    @Volatile
    private var lastFailedAttemptTime: Long = 0

    private const val MAX_FAILED_ATTEMPTS = 3
    private const val FAILSAFE_RESET_MS = 60_000  // Reset after 1 minute
}

private fun isPluginConnected(): Boolean {
    // Reset failsafe after timeout
    val now = System.currentTimeMillis()
    if (failedAttempts >= MAX_FAILED_ATTEMPTS &&
        now - lastFailedAttemptTime > FAILSAFE_RESET_MS) {
        Log.i(TAG, "üîÑ Resetting failsafe mode after ${FAILSAFE_RESET_MS/1000}s timeout")
        failedAttempts = 0
    }

    // Check failsafe
    if (failedAttempts >= MAX_FAILED_ATTEMPTS) {
        Log.d(TAG, "‚ö†Ô∏è Plugin connection disabled (failsafe mode)")
        return false
    }

    // ... cache check ...

    // Perform ping
    val connected = try {
        // ... ping logic ...
        success
    } catch (e: Exception) {
        Log.d(TAG, "‚ö†Ô∏è Plugin not reachable: ${e.message}")
        failedAttempts++
        lastFailedAttemptTime = now  // Track last failure ‚≠ê
        Log.d(TAG, "Failed attempts: $failedAttempts / $MAX_FAILED_ATTEMPTS")
        false
    }

    // ...
}
```

**Beneficios**:
- ‚úÖ Auto-recovery: interceptor se auto-recupera despu√©s de 1 minuto
- ‚úÖ Usuario NO necesita reiniciar app
- ‚úÖ Mejor UX: plugin puede reiniciarse sin afectar app
- ‚úÖ Mantiene failsafe para protecci√≥n, pero no permanente

**Esfuerzo**: ~0.5 horas
**Prioridad**: üü° ALTA (es un bug de UX)

---

## üìä Resumen - Problema #9: MockkHttpInterceptor Optimizations

| Sub-problema | Impacto | Mejora | Esfuerzo |
|--------------|---------|--------|----------|
| 9.1: BuildConfig Reflection | üî¥ Cr√≠tico | 1-5ms ‚Üí 0.01ms por request | 1h |
| 9.2: Socket Pool | üî¥ Cr√≠tico | 10-50ms ‚Üí 1ms por request | 3h |
| 9.3: peekBody() Limit | üî¥ Cr√≠tico | 100-500ms ‚Üí 5ms, 5MB ‚Üí 100KB | 2h |
| 9.4: Batching (Coroutines) | üü° Alta | 100 sockets ‚Üí 2-3, 100 threads ‚Üí 1 | 4h |
| 9.5: Headers.toMap() | üü¢ Baja | ~0.5ms por request | 0.5h |
| 9.6: failedAttempts Reset | üü° Alta (bug) | Evita stuck permanente | 0.5h |

**Total Esfuerzo**: ~11 horas

**Impacto Combinado**:
- **Latencia por request**: 111-555ms ‚Üí ~6ms (**18-92x m√°s r√°pido**)
- **Memoria por request**: 5MB ‚Üí 100KB (**50x menos memoria**)
- **Threads**: 100 ‚Üí 1 (**100x menos threads**)
- **Sockets**: 100 ‚Üí 2-3 con reuso (**33-50x menos sockets**)

**Prioridad General**: üî¥ **CR√çTICA** (especialmente 9.1, 9.2, 9.3)

---

## üìã Resumen de Prioridades

### üî¥ **CR√çTICO** (Hacer primero - ~36 horas total)
1. ‚úÖ **Coroutines + Channel en GlobalServer** ‚Üí 3h
2. ‚úÖ **Debug Mode Non-Blocking con CompletableDeferred** ‚Üí 7h
3. ‚úÖ **FlowStore Memory Management** ‚Üí 4h
4. ‚úÖ **UI Batching con Flow (reactive streams)** ‚Üí 5h
5. ‚úÖ **ADB Async Operations con parallel processing** ‚Üí 4h
6. ‚úÖ **Agregar dependencia kotlinx-coroutines** ‚Üí 2h
7. ‚úÖ **MockkHttpInterceptor - Sub-problemas 9.1, 9.2, 9.3** ‚Üí 6h
8. ‚úÖ **MockkHttpInterceptor - Sub-problemas 9.4, 9.5, 9.6** ‚Üí 5h

### üü° **ALTA PRIORIDAD** (Hacer despu√©s - ~7.5 horas total)
9. ‚úÖ **Mockk Rules Indexing** ‚Üí 4h
10. ‚úÖ **Logging Optimization** ‚Üí 2h
11. ‚úÖ **Android Interceptor con Coroutines** ‚Üí 1.5h

### üü¢ **MEJORAS ADICIONALES** (Opcional - futuro)
- Virtual Scrolling para listas muy grandes
- Compresi√≥n de flows con GZIP
- M√©tricas de performance en UI
- "Light Mode" para apps con tr√°fico masivo

---

## üéØ Estrategia de Implementaci√≥n

### Pre-requisito: Agregar Dependencia de Coroutines
```kotlin
// build.gradle.kts
dependencies {
    implementation("org.jetbrains.kotlinx:kotlinx-coroutines-core:1.9.0")
    implementation("org.jetbrains.kotlinx:kotlinx-coroutines-swing:1.9.0") // Para Dispatchers.EDT
}
```

### Fase 1 (Semana 1-2): Arreglos Cr√≠ticos con Coroutines
**Orden recomendado**:
1. **Agregar dependencia de coroutines** (2h) - prerequisito
2. **Coroutines + Channel en GlobalServer** (3h) - base fundamental, elimina thread explosion
3. **FlowStore Memory Management** (4h) - previene OutOfMemory, independiente de coroutines
4. **UI Batching con Flow** (5h) - UI responsive, usa reactive streams
5. **ADB Async con parallel processing** (4h) - previene bloqueos de IDE, paraleliza operaciones
6. **Debug Mode Non-Blocking** (7h) - feature m√°s compleja, usa CompletableDeferred

**Total Fase 1**: ~25 horas de trabajo

### Fase 2 (Semana 3): Optimizaciones
7. **Mockk Rules Indexing** (4h) - mejora matching performance
8. **Logging Optimization** (2h) - reduce overhead de logs
9. **Android Interceptor con Coroutines** (1.5h) - optimiza app Android

**Total Fase 2**: ~7.5 horas

### Fase 3: Testing Integral
- Crear app de prueba que genere 100+ requests/segundo
- Probar con m√∫ltiples proyectos abiertos simult√°neamente
- Monitorear memoria y CPU durante carga alta
- Verificar que Debug Mode no bloquea con muchas requests
- Stress test: 500+ requests simult√°neas
- Memory profiling: verificar que memoria se mantiene bajo 100MB

---

## üìä M√©tricas de √âxito

**Antes de las optimizaciones**:
- ‚ùå 100 requests simult√°neas ‚Üí Plugin collapsa
- ‚ùå Debug Mode con 10+ requests ‚Üí App Android se congela
- ‚ùå Refresh Apps ‚Üí Android Studio bloqueado 2-5 minutos
- ‚ùå UI se congela con alto tr√°fico
- ‚ùå Memoria crece sin control

**Despu√©s de las optimizaciones**:
- ‚úÖ 500+ requests simult√°neas ‚Üí Plugin responde correctamente
- ‚úÖ Debug Mode con 50+ requests ‚Üí Queuing funciona, app no se congela
- ‚úÖ Refresh Apps ‚Üí Background loading, IDE responsive
- ‚úÖ UI fluida incluso con cientos de requests
- ‚úÖ Memoria estable bajo 100MB

---

## üõ†Ô∏è Herramientas de Monitoreo (a agregar)

```kotlin
// Panel de estad√≠sticas en InspectorPanel
class PerformanceStatsPanel : JPanel() {
    private val threadsLabel = JLabel("Threads: 0")
    private val memoryLabel = JLabel("Memory: 0 MB")
    private val requestsPerSecLabel = JLabel("Requests/s: 0")
    private val queueSizeLabel = JLabel("Queue: 0")

    init {
        layout = FlowLayout(FlowLayout.LEFT)
        add(threadsLabel)
        add(memoryLabel)
        add(requestsPerSecLabel)
        add(queueSizeLabel)

        // Update every second
        Timer(1000) {
            updateStats()
        }.apply { isRepeating = true }.start()
    }

    private fun updateStats() {
        val runtime = Runtime.getRuntime()
        val usedMemory = (runtime.totalMemory() - runtime.freeMemory()) / (1024 * 1024)

        memoryLabel.text = "Memory: $usedMemory MB"
        // ... otros stats
    }
}
```

---

---

## üî¨ Comparativa: ExecutorService vs Kotlin Coroutines

### ¬øPor qu√© Coroutines en lugar de ExecutorService?

| Aspecto | ExecutorService (Tradicional) | **Kotlin Coroutines** (Recomendado) |
|---------|-------------------------------|--------------------------------------|
| **Memoria** | 50 threads = ~50MB | 50 coroutines = ~500KB | ‚úÖ 100x menos memoria
| **Escalabilidad** | ~1,000 threads m√°ximo antes de colapso | 100,000+ coroutines sin problemas | ‚úÖ Escala masivamente
| **Context Switching** | Alto overhead de CPU | Minimal (cooperativo, no preemptivo) | ‚úÖ M√°s eficiente
| **Backpressure** | Manual (BlockingQueue) | Built-in (Channel, Flow) | ‚úÖ Nativo
| **Cancelaci√≥n** | Manual (interrupts, flags) | Structured concurrency (autom√°tica) | ‚úÖ Segura y limpia
| **IntelliJ Integration** | B√°sica | Nativa (Dispatchers.EDT) | ‚úÖ Primera clase
| **Reactive Streams** | Necesita RxJava/Reactor | Flow nativo | ‚úÖ Integrado
| **C√≥digo** | Verboso (callbacks, try/finally) | Conciso (suspending functions) | ‚úÖ M√°s legible
| **Debugging** | Complicado (stack traces mezcladas) | IntelliJ Coroutines Debugger | ‚úÖ Mejor tooling
| **Timeout** | Manual (`Future.get(timeout)`) | Built-in (`withTimeout()`) | ‚úÖ Simple
| **Parallel Processing** | Manual (`invokeAll()`) | `async {}.awaitAll()` | ‚úÖ Declarativo
| **Esfuerzo migraci√≥n** | ~20 horas | ~25 horas | ‚ö†Ô∏è +5 horas

### Ventajas Clave de Coroutines

#### 1. **Lightweight y Escalabilidad**
```kotlin
// ExecutorService: Limitado por threads del OS
val executor = Executors.newFixedThreadPool(50)  // M√°ximo pr√°ctico
// 50 threads = ~50MB de memoria

// Coroutines: Limitado solo por memoria
repeat(100_000) {
    launch { /* task */ }  // 100,000 coroutines = ~10MB
}
```

#### 2. **Backpressure Nativo**
```kotlin
// ExecutorService: Manual
val queue = LinkedBlockingQueue<Task>(500)
if (!queue.offer(task)) {
    // Rechazar manualmente
}

// Coroutines: Built-in
val channel = Channel<Task>(capacity = 500)
channel.send(task)  // Suspende si est√° lleno (no bloquea thread!)
```

#### 3. **Structured Concurrency**
```kotlin
// ExecutorService: Cleanup manual
executor.shutdown()
if (!executor.awaitTermination(60, TimeUnit.SECONDS)) {
    executor.shutdownNow()
}

// Coroutines: Autom√°tico
scope.cancel()  // Cancela TODAS las coroutines inmediatamente
```

#### 4. **Reactive Streams Nativos**
```kotlin
// ExecutorService + RxJava (dependencia externa)
Observable.create<Flow> { emitter ->
    // ...
}.buffer(50)
 .debounce(300, TimeUnit.MILLISECONDS)
 .observeOn(AndroidSchedulers.mainThread())

// Coroutines: Flow nativo
flowStore.flowAdded
    .buffer(50)
    .debounce(300)
    .flowOn(Dispatchers.Main)
```

#### 5. **Parallel Processing Declarativo**
```kotlin
// ExecutorService: Verboso
val futures = packageNames.map { pkg ->
    executor.submit(Callable { processPackage(pkg) })
}
val results = futures.map { it.get() }  // Bloquea

// Coroutines: Elegante
val results = packageNames.map { pkg ->
    async { processPackage(pkg) }
}.awaitAll()  // No bloquea, suspende
```

### ¬øCu√°ndo usar cada uno?

#### Usar ExecutorService si:
- ‚ùå No quieres agregar dependencia de coroutines
- ‚ùå El equipo no conoce coroutines
- ‚ùå Proyecto legacy con mucho c√≥digo usando threads

#### Usar Coroutines si:
- ‚úÖ Necesitas alta concurrencia (100s-1000s de tasks)
- ‚úÖ Quieres c√≥digo m√°s limpio y mantenible
- ‚úÖ Necesitas reactive streams (Flow)
- ‚úÖ Trabajas en Kotlin (IntelliJ Platform)
- ‚úÖ Necesitas backpressure y cancelaci√≥n robusta
- ‚úÖ **Es un proyecto nuevo o refactor** ‚Üê **Tu caso**

### Trade-off: Tiempo de Implementaci√≥n

| Fase | ExecutorService | Coroutines | Diferencia |
|------|-----------------|------------|------------|
| Setup | 0h | +2h (agregar deps) | +2h |
| Problema #1 | 2h | 3h | +1h |
| Problema #2 | 6h | 7h | +1h |
| Problema #4 | 5h | 5h | 0h |
| Problema #5 | 3h | 4h | +1h |
| **Total** | **20h** | **25h** | **+5h** |

**Conclusi√≥n**: +5 horas de inversi√≥n inicial para una arquitectura **mucho mejor** a largo plazo.

### Recomendaci√≥n Final

**Usa Coroutines** porque:

1. ‚úÖ **Performance superior**: Menos memoria, m√°s escalable
2. ‚úÖ **C√≥digo m√°s limpio**: Suspending functions vs callbacks
3. ‚úÖ **Mejor integraci√≥n**: IntelliJ Platform est√° migrando a coroutines
4. ‚úÖ **Futureproof**: Coroutines es el est√°ndar en Kotlin ecosystem
5. ‚úÖ **+5 horas iniciales valen la pena**: Evita refactor futuro

El plugin funcionar√° **mejor con Coroutines** y ser√° **m√°s f√°cil de mantener** a largo plazo.

---

**Documento creado**: 2025-01-08
**√öltima actualizaci√≥n**: 2025-01-08
**Estado**: Pendiente de implementaci√≥n
**Decisi√≥n arquitect√≥nica**: Usar Kotlin Coroutines en lugar de ExecutorService tradicional
